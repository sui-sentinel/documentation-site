---
title: 'Broader Use Cases'
description: ''
---

## Use Cases & Applications

### For AI Companies & Model Deployers

**Pre-Production Security Validation**

Before launching a new model or feature, deploy a Sentinel with a substantial bounty. Let the global security community test it for a defined period. If thousands of skilled researchers cannot break it, you have empirical evidence of robustness—not just internal assurances.

_Real-world scenario_: A healthcare AI company deploys a HIPAA-compliant medical chatbot as a Sentinel with a 10,000 SUI bounty. After 30 days and 847 failed attack attempts from security researchers worldwide, they can launch to production with documented proof of adversarial testing and regulatory evidence of due diligence.

**Continuous Production Monitoring**

Security isn't a one-time event. Keep Sentinels active post-launch to detect emerging vulnerabilities as new attack techniques develop.

_Real-world scenario_: A financial advisory LLM maintains a permanent 1,000 SUI Sentinel. When a novel jailbreak technique emerges in the wild, security researchers discover it works against the Sentinel within 72 hours—allowing the company to patch their production system before any user is affected.

**Competitive Benchmarking**

Demonstrate your model's superiority through verifiable security metrics rather than marketing claims.

_Real-world scenario_: Two competing AI platforms both deploy Sentinels. Platform A's model survives 2,000 attacks before first successful jailbreak. Platform B's survives 500. These are cryptographically verifiable facts, not subjective claims.

**Regulatory Compliance**

Generate auditable security reports using on-chain records to satisfy regulatory requirements for AI safety testing.

_Real-world scenario_: An EU-based AI company needs to demonstrate GDPR compliance. They reference their Sentinel's on-chain history: "Our data protection model withstood 1,247 adversarial attacks over Q4 2025, with zero successful data exfiltration attempts, as documented in Sui transactions."

### For Security Researchers & Red Teamers

**Monetize Specialized Skills**

Turn your prompt engineering expertise into direct income without employment overhead or business development.

_Real-world scenario_: A security researcher discovers a novel Unicode-based encoding technique that bypasses most content filters. Within one week, they successfully attack 15 different Sentinels using variations of this technique, earning 8,000 SUI (approximately $8,000-$80,000 depending on SUI price).

**Build Verifiable Reputation**

Every successful attack is permanently attributed to your address on-chain, creating an unforgeable resume of capabilities.

_Real-world scenario_: A researcher's wallet address shows 47 successful jailbreaks against high-bounty Sentinels, including three against models from major AI labs. This leads to consulting contracts, conference speaking invitations, and job offers—all based on cryptographically verifiable accomplishments.

**Advance AI Safety Research**

Contribute to the public good by discovering vulnerabilities before malicious actors exploit them in production systems.

_Real-world scenario_: A researcher discovers a subtle prompt injection technique that could be used for phishing. Instead of weaponizing it, they demonstrate it through Sui Sentinel, earning bounties while alerting the entire AI industry to the vulnerability class.

**Learn Through Practice**

Improve your skills by studying others' attack patterns and testing your techniques against diverse models.

### For the Broader AI Ecosystem

**Transparent Benchmarking**

Create industry-standard security benchmarks based on real adversarial testing rather than curated static datasets.

**Knowledge Sharing**

Build a public database of attack techniques and defense strategies that benefits the entire AI safety community.

**Economic Alignment**

Transform AI security from a cost center into a potential revenue stream, incentivizing organizations to prioritize safety.

**Decentralized Red Teaming**

Access global security talent without geographic or institutional barriers, democratizing access to AI safety expertise.
